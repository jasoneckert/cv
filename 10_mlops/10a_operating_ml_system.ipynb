{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512034c4-1d56-463e-b23b-6c07b7818d18",
   "metadata": {},
   "source": [
    "# Operating a Vision Model as a Living System\n",
    "\n",
    "In previous chapters, we learned how to:\n",
    "\n",
    "- Train a computer vision model\n",
    "- Evaluate its performance\n",
    "- Deploy it using FastAPI and containers\n",
    "- Monitor for drift\n",
    "- Explain predictions using Grad-CAM\n",
    "\n",
    "In this notebook, we shift perspective.\n",
    "\n",
    "Instead of focusing on *training a model*, we focus on **operating a model over time**.\n",
    "\n",
    "In the real world, models:\n",
    "\n",
    "- Experience data drift\n",
    "- Require retraining\n",
    "- Must be versioned\n",
    "- Need promotion decisions\n",
    "- Should not automatically replace previous models\n",
    "\n",
    "We will simulate a simple “production lifecycle”:\n",
    "\n",
    "1. Train baseline model (v1)\n",
    "2. Save artifacts + metadata\n",
    "3. Simulate new incoming data\n",
    "4. Detect drift\n",
    "5. Retrain (v2)\n",
    "6. Compare v1 vs v2\n",
    "7. Decide whether to promote\n",
    "\n",
    "This notebook runs fully locally using `tensorflow_datasets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81cb0087-c50e-41d9-9916-dac820b6f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "Classes: ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from datetime import datetime\n",
    "from scipy.stats import entropy\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "IMG_SIZE = 160\n",
    "BATCH_SIZE = 32\n",
    "MODEL_DIR = \"model_registry\"\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load Dataset\n",
    "\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
    "CLASS_NAMES = ds_info.features[\"label\"].names\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Classes:\", CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53ee273-a3c2-433f-9d7b-3aafe2044a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_160 (Funct  (None, 5, 5, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model (Transfer Learning)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45b1644-0a24-4e75-83b8-99ef01b090ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "92/92 [==============================] - 17s 153ms/step - loss: 0.7673 - accuracy: 0.7204 - val_loss: 0.4742 - val_accuracy: 0.8297\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 14s 147ms/step - loss: 0.3874 - accuracy: 0.8716 - val_loss: 0.3877 - val_accuracy: 0.8569\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 13s 142ms/step - loss: 0.3016 - accuracy: 0.9029 - val_loss: 0.3527 - val_accuracy: 0.8747\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.3527 - accuracy: 0.8747\n",
      "Validation accuracy (v1): 0.8746594190597534\n"
     ]
    }
   ],
   "source": [
    "# Train Baseline Model (v1)\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(ds_val)\n",
    "print(\"Validation accuracy (v1):\", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95bcd80-3020-4e7a-9e39-32a7bb03f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_160_input with unsupported characters which will be renamed to mobilenetv2_1_00_160_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_registry\\v1\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_registry\\v1\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model version: v1\n"
     ]
    }
   ],
   "source": [
    "# Save Model + Metadata (Model Registry Simulation)\n",
    "\n",
    "version = \"v1\"\n",
    "version_path = os.path.join(MODEL_DIR, version)\n",
    "os.makedirs(version_path, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(version_path, \"model\"))\n",
    "\n",
    "metadata = {\n",
    "    \"version\": version,\n",
    "    \"timestamp\": str(datetime.now()),\n",
    "    \"validation_accuracy\": float(val_acc)\n",
    "}\n",
    "\n",
    "with open(os.path.join(version_path, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Saved model version:\", version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39299906-c2cc-45b7-bfd7-d501889b313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 4s 162ms/step - loss: 0.4875 - accuracy: 0.8161\n",
      "Accuracy on drifted data: 0.8160762786865234\n"
     ]
    }
   ],
   "source": [
    "# Simulate Incoming Drifted Data (we artificially introduce brightness shift)\n",
    "\n",
    "def simulate_drift(image, label):\n",
    "    image = tf.image.adjust_brightness(image, delta=0.3)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "ds_drift = ds_val.unbatch().map(simulate_drift).batch(BATCH_SIZE)\n",
    "\n",
    "# Evaluate Drift Impact\n",
    "\n",
    "drift_loss, drift_acc = model.evaluate(ds_drift)\n",
    "print(\"Accuracy on drifted data:\", drift_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546d76a3-c003-44f8-88ab-5e614b34e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence between original and drifted predictions: 0.004618276\n"
     ]
    }
   ],
   "source": [
    "# Simple Drift Detection (KL Divergence)\n",
    "\n",
    "def get_prediction_distribution(dataset):\n",
    "    preds = []\n",
    "    for images, _ in dataset:\n",
    "        p = model.predict(images, verbose=0)\n",
    "        preds.append(p)\n",
    "    preds = np.vstack(preds)\n",
    "    return preds.mean(axis=0)\n",
    "\n",
    "dist_original = get_prediction_distribution(ds_val)\n",
    "dist_drifted = get_prediction_distribution(ds_drift)\n",
    "\n",
    "kl_div = entropy(dist_original, dist_drifted)\n",
    "print(\"KL Divergence between original and drifted predictions:\", kl_div)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbecac-2cfd-44db-b6c3-9ad6ea59370d",
   "metadata": {},
   "source": [
    "## Decision Point\n",
    "\n",
    "If performance degrades significantly and drift is detected,\n",
    "we may choose to retrain.\n",
    "\n",
    "This is not automatic — it requires a governance decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff7a5e7-22b0-464c-a316-beb2d77440f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23/23 [==============================] - 5s 117ms/step - loss: 1.6090 - accuracy: 0.2275\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 1.6076 - accuracy: 0.2534\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 1.6065 - accuracy: 0.2534\n",
      "23/23 [==============================] - 4s 119ms/step - loss: 1.6057 - accuracy: 0.2534\n",
      "Validation accuracy (v2): 0.25340598821640015\n"
     ]
    }
   ],
   "source": [
    "# Retrain as Version v2\n",
    "\n",
    "model_v2 = tf.keras.models.clone_model(model)\n",
    "model_v2.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_v2.fit(ds_drift, epochs=3)\n",
    "\n",
    "v2_loss, v2_acc = model_v2.evaluate(ds_val)\n",
    "print(\"Validation accuracy (v2):\", v2_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a562a4f-afc7-4a53-bd3d-7a620a5df328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_160_input with unsupported characters which will be renamed to mobilenetv2_1_00_160_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_registry\\v2\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_registry\\v2\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model version: v2\n"
     ]
    }
   ],
   "source": [
    "# Save v2\n",
    "\n",
    "version = \"v2\"\n",
    "version_path = os.path.join(MODEL_DIR, version)\n",
    "os.makedirs(version_path, exist_ok=True)\n",
    "\n",
    "model_v2.save(os.path.join(version_path, \"model\"))\n",
    "\n",
    "metadata = {\n",
    "    \"version\": version,\n",
    "    \"timestamp\": str(datetime.now()),\n",
    "    \"validation_accuracy\": float(v2_acc)\n",
    "}\n",
    "\n",
    "with open(os.path.join(version_path, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Saved model version:\", version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41dd6ca-2fd1-44b4-ae9a-143221b5d55d",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "You have simulated:\n",
    "\n",
    "- Model versioning\n",
    "- Drift detection\n",
    "- Performance degradation\n",
    "- Retraining\n",
    "- Promotion decision logic\n",
    "\n",
    "This is what happens in real ML systems over months or years.\n",
    "\n",
    "The important takeaway: ***Training a model is not the end of the workflow — it is the beginning of a lifecycle.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24376f56-657d-448c-be59-8095ab8279bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
