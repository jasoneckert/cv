{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# 06_02_engineering_reusable_pipelines.ipynb\n",
    "\n",
    "# Engineering Reusable Pipelines\n",
    "- Create reusable preprocessing classes\n",
    "- Compare Python-level vs model-level preprocessing\n",
    "- Understand deployment implications\n",
    "- Save and reload a model safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load dataset\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "class_names = ds_info.features[\"label\"].names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
   },
   "outputs": [],
   "source": [
    "# Create a Reusable Preprocessor Class \n",
    "\n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, img_size=(160, 160)):\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def resize(self, image):\n",
    "        return tf.image.resize(image, self.img_size)\n",
    "\n",
    "    def normalize(self, image):\n",
    "        return image / 255.0\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        image = self.resize(image)\n",
    "        image = self.normalize(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LKXV5oRmkSTK"
   },
   "outputs": [],
   "source": [
    "# Apply it\n",
    "\n",
    "preprocessor = ImagePreprocessor()\n",
    "\n",
    "train_ds = (\n",
    "    ds_train\n",
    "    .map(preprocessor)\n",
    "    .shuffle(1000)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- What happens if someone forgets to use this class at inference time?\n",
    "- Is this guaranteed to be applied in production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Preprocessing to Keras Layers\n",
    "\n",
    "preprocessing_block = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(160, 160),\n",
    "    tf.keras.layers.Rescaling(1./255)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "# Preprocessing block inside the model\n",
    "preprocessing_block = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(160, 160),\n",
    "    tf.keras.layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "# Base model (CPU friendly)\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(160, 160, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Full model\n",
    "model_with_preprocessing = tf.keras.Sequential([\n",
    "    preprocessing_block,\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_with_preprocessing.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 17s 145ms/step - loss: 0.7740 - accuracy: 0.7095 - val_loss: 0.4680 - val_accuracy: 0.8379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ccb69d9540>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train for 1 epoch before saving\n",
    "\n",
    "train_raw = (\n",
    "    ds_train\n",
    "    .map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y))\n",
    "    .shuffle(1000)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_raw = (\n",
    "    ds_val\n",
    "    .map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y))\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "model_with_preprocessing.fit(\n",
    "    train_raw,\n",
    "    validation_data=val_raw,\n",
    "    epochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: flower_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: flower_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save and Reload Model\n",
    "\n",
    "model_with_preprocessing.save(\"flower_model\")\n",
    "\n",
    "reloaded_model = tf.keras.models.load_model(\"flower_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tulips\n"
     ]
    }
   ],
   "source": [
    "# Test inference on a raw image:\n",
    "\n",
    "reloaded_model = tf.keras.models.load_model(\"flower_model\")\n",
    "\n",
    "for image, label in ds_val.take(1):\n",
    "    resized = tf.image.resize(image, (160, 160))\n",
    "    prediction = reloaded_model(tf.expand_dims(resized, 0))\n",
    "    print(\"Predicted class:\", class_names[np.argmax(prediction)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- Embedding preprocessing in the model ensures:\n",
    "  - Reproducibility\n",
    "  - Portability\n",
    "  - Production safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
