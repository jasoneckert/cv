{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70602bd4-6292-4c26-91ef-fe735f402aba",
   "metadata": {},
   "source": [
    "# TFRecord Serialization (Without Apache Beam)\n",
    "\n",
    "In this notebook, we learn how to:\n",
    "- Write TFRecord files\n",
    "- Parse TFRecord files\n",
    "- Compare performance to raw image loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858ed698-8bb3-4a55-8091-3c9f86e779ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord file written to: sample_tf_flowers.tfrecord\n",
      "Serialized example type: <class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# ---------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "TFRECORD_PATH = \"sample_tf_flowers.tfrecord\"\n",
    "\n",
    "# ---------------------------------\n",
    "# Load small subset of dataset\n",
    "# ---------------------------------\n",
    "train_raw = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=\"train[:10%]\",\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# Preprocessing\n",
    "# ---------------------------------\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_ds = (\n",
    "    train_raw\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# TFRecord Serialization Function\n",
    "# ---------------------------------\n",
    "def serialize_example(image, label):\n",
    "    # Convert back to uint8 for JPEG encoding\n",
    "    image = tf.cast(image * 255.0, tf.uint8)\n",
    "\n",
    "    # Encode to JPEG and convert to raw bytes\n",
    "    image_bytes = tf.io.encode_jpeg(image).numpy()\n",
    "\n",
    "    feature = {\n",
    "        \"image\": tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[image_bytes])\n",
    "        ),\n",
    "        \"label\": tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=[int(label.numpy())])\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(feature=feature)\n",
    "    )\n",
    "\n",
    "    return example.SerializeToString()\n",
    "\n",
    "# ---------------------------------\n",
    "# Write TFRecord File\n",
    "# ---------------------------------\n",
    "with tf.io.TFRecordWriter(TFRECORD_PATH) as writer:\n",
    "    for image, label in train_ds.unbatch():\n",
    "        serialized = serialize_example(image, label)\n",
    "        writer.write(serialized)\n",
    "\n",
    "print(f\"TFRecord file written to: {TFRECORD_PATH}\")\n",
    "\n",
    "# ---------------------------------\n",
    "# Quick Verification\n",
    "# ---------------------------------\n",
    "for image, label in train_ds.unbatch().take(1):\n",
    "    serialized = serialize_example(image, label)\n",
    "    print(\"Serialized example type:\", type(serialized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171adf5e-8055-4d53-9a60-c2c9ed3a8e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord file created.\n",
      "File size (KB): 2448.78\n"
     ]
    }
   ],
   "source": [
    "# Write file\n",
    "\n",
    "tfrecord_path = \"flowers.tfrecord\"\n",
    "\n",
    "with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "    for image, label in train_ds.unbatch().take(100):\n",
    "        writer.write(serialize_example(image, label))\n",
    "\n",
    "print(\"TFRecord file created.\")\n",
    "print(\"File size (KB):\", round(os.path.getsize(tfrecord_path) / 1024, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc79849e-db08-46ca-afd4-0de833d41920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in TFRecord: 100\n"
     ]
    }
   ],
   "source": [
    "# Read TFRecord\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed[\"image\"], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, parsed[\"label\"]\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(\"flowers.tfrecord\")\n",
    "parsed_dataset = raw_dataset.map(parse_example)\n",
    "\n",
    "record_count = 0\n",
    "for _ in raw_dataset:\n",
    "    record_count += 1\n",
    "\n",
    "print(\"Number of records in TFRecord:\", record_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bc9c4a-56b4-4f0d-bf4b-8b737caa3a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord time: 0.03161787986755371\n"
     ]
    }
   ],
   "source": [
    "# Compare speed\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for _ in parsed_dataset.batch(32).take(10):\n",
    "    pass\n",
    "print(\"TFRecord time:\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5557b7-08d4-4f5e-a242-c64fb91c9662",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "- TFRecords improve scalability and consistency.\n",
    "- For small local experiments, raw images are fine.\n",
    "- For large production systems, serialized datasets are essential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0ef90-cc1d-4d77-87b9-aad24dc106e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
