{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "Dataset loaded:\n",
      "tfds.core.DatasetInfo(\n",
      "    name='tf_flowers',\n",
      "    full_name='tf_flowers/3.0.1',\n",
      "    description=\"\"\"\n",
      "    A large set of images of flowers\n",
      "    \"\"\",\n",
      "    homepage='https://www.tensorflow.org/tutorials/load_data/images',\n",
      "    data_dir='C:\\\\Users\\\\Jason Eckert\\\\tensorflow_datasets\\\\tf_flowers\\\\3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=218.21 MiB,\n",
      "    dataset_size=221.83 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=5),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    nondeterministic_order=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=3670, num_shards=2>,\n",
      "    },\n",
      "    citation=\"\"\"@ONLINE {tfflowers,\n",
      "    author = \"The TensorFlow Team\",\n",
      "    title = \"Flowers\",\n",
      "    month = \"jan\",\n",
      "    year = \"2019\",\n",
      "    url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\"\"\",\n",
      ")\n",
      "Training and validation datasets ready.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 43s 1us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flower_prob (Dense)         (None, 5)                 10245     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,871,725\n",
      "Trainable params: 7,336,621\n",
      "Non-trainable params: 13,535,104\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "184/184 [==============================] - 171s 913ms/step - loss: 0.5666 - accuracy: 0.8106 - val_loss: 0.2423 - val_accuracy: 0.9142\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 170s 925ms/step - loss: 0.2046 - accuracy: 0.9360 - val_loss: 0.2450 - val_accuracy: 0.9196\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 169s 915ms/step - loss: 0.1055 - accuracy: 0.9724 - val_loss: 0.1722 - val_accuracy: 0.9360\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 170s 926ms/step - loss: 0.0619 - accuracy: 0.9860 - val_loss: 0.1763 - val_accuracy: 0.9428\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 173s 940ms/step - loss: 0.0362 - accuracy: 0.9935 - val_loss: 0.1891 - val_accuracy: 0.9360\n",
      "Saved training history to 03b_xception_finetune_outputs\\xception_training_history.csv\n",
      "Saved evaluation artifacts:\n",
      "- 03b_xception_finetune_outputs\\xception_predictions.csv\n",
      "- 03b_xception_finetune_outputs\\confusion_matrix_raw.csv\n",
      "- 03b_xception_finetune_outputs\\confusion_matrix_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Fine-Tuning Xception (TFDS, Local, CPU-Friendly)\n",
    "# ============================================================\n",
    "#\n",
    "# This notebook demonstrates fine-tuning using a deeper\n",
    "# architecture (Xception) and contrasts it with MobileNetV2.\n",
    "#\n",
    "# IMPORTANT:\n",
    "# ----------\n",
    "# - We use tf_flowers (5 classes) via TFDS\n",
    "# - We DO NOT run learning-rate decay experiments\n",
    "# - We fine-tune ONLY the top layers for performance\n",
    "#\n",
    "# This keeps the notebook runnable on student laptops\n",
    "# while preserving the core learning objective.\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Imports\n",
    "# ----------------------------\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 16          # Reduced for Xception on CPU\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Number of top layers to fine-tune\n",
    "FINE_TUNE_AT = 20\n",
    "\n",
    "CLASS_NAMES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "\n",
    "OUTPUT_DIR = \"03b_xception_finetune_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Load Dataset (TFDS)\n",
    "# ============================================================\n",
    "\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "print(\"Dataset loaded:\")\n",
    "print(ds_info)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Preprocessing Pipeline\n",
    "# ============================================================\n",
    "#\n",
    "# Xception expects:\n",
    "# - 224x224 RGB images\n",
    "# - Float32 inputs\n",
    "# - Xception-specific preprocessing\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    image = tf.keras.applications.xception.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_ds = (\n",
    "    ds_train\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .shuffle(1000)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    ds_val\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(\"Training and validation datasets ready.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build Fine-Tuned Xception Model\n",
    "# ============================================================\n",
    "#\n",
    "# Strategy:\n",
    "# - Load Xception pretrained on ImageNet\n",
    "# - Freeze most layers\n",
    "# - Fine-tune only the top N layers\n",
    "#\n",
    "# Xception is significantly heavier than MobileNetV2,\n",
    "# so careful fine-tuning is essential on CPU.\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "def build_finetuned_xception(\n",
    "    fine_tune_at=20,\n",
    "    learning_rate=1e-4\n",
    "):\n",
    "    base_model = tf.keras.applications.Xception(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    )\n",
    "\n",
    "    for layer in base_model.layers[:-fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in base_model.layers[-fine_tune_at:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(len(CLASS_NAMES), activation=\"softmax\", name=\"flower_prob\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_finetuned_xception(\n",
    "    fine_tune_at=FINE_TUNE_AT,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train Model\n",
    "# ============================================================\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Save Training History (CSV)\n",
    "# ============================================================\n",
    "\n",
    "def save_training_history(history, filename):\n",
    "    df = pd.DataFrame(history.history)\n",
    "    path = os.path.join(OUTPUT_DIR, filename)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved training history to {path}\")\n",
    "\n",
    "\n",
    "save_training_history(history, \"xception_training_history.csv\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Evaluate Predictions and Confusion Matrices\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_and_save(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        probs = model.predict(images, verbose=0)\n",
    "        preds = tf.argmax(probs, axis=1)\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Per-sample predictions\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"true_label\": [CLASS_NAMES[i] for i in y_true],\n",
    "        \"predicted_label\": [CLASS_NAMES[i] for i in y_pred]\n",
    "    })\n",
    "\n",
    "    pred_path = os.path.join(OUTPUT_DIR, \"xception_predictions.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    # Confusion matrix (raw)\n",
    "    cm = tf.math.confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        num_classes=len(CLASS_NAMES)\n",
    "    ).numpy()\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=CLASS_NAMES, columns=CLASS_NAMES)\n",
    "    cm_path = os.path.join(OUTPUT_DIR, \"confusion_matrix_raw.csv\")\n",
    "    cm_df.to_csv(cm_path)\n",
    "\n",
    "    # Normalized confusion matrix\n",
    "    cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    cm_norm_df = pd.DataFrame(cm_norm, index=CLASS_NAMES, columns=CLASS_NAMES)\n",
    "    cm_norm_path = os.path.join(OUTPUT_DIR, \"confusion_matrix_normalized.csv\")\n",
    "    cm_norm_df.to_csv(cm_norm_path)\n",
    "\n",
    "    print(\"Saved evaluation artifacts:\")\n",
    "    print(\"-\", pred_path)\n",
    "    print(\"-\", cm_path)\n",
    "    print(\"-\", cm_norm_path)\n",
    "\n",
    "\n",
    "evaluate_and_save(model, val_ds)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "#\n",
    "# - Xception is deeper and more computationally expensive\n",
    "#   than MobileNetV2\n",
    "# - Partial fine-tuning balances performance and runtime\n",
    "# - Architecture choice impacts training time and behavior\n",
    "#\n",
    "# This concludes the comparison of transfer learning and\n",
    "# fine-tuning strategies in Chapter 3.\n",
    "#\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-4.m60",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-4:m60"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
