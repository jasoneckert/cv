{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9a223d-4739-4cb3-ab53-d45c1612f108",
   "metadata": {},
   "source": [
    "# Object Detection with Pascal VOC and Pretrained SSD\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Explain the difference between image classification and object detection\n",
    "- Interpret bounding box annotations in TFDS\n",
    "- Visualize bounding boxes on images\n",
    "- Run inference using a pretrained SSD MobileNet model\n",
    "  - SSD = Single Shot Detector\n",
    "  - MobileNet = Lightweight CNN backbone\n",
    "- Understand the role of confidence scores and Non-Max Suppression (NMS)\n",
    "\n",
    "In previous chapters, our model predicted: Input Image → One Label (e.g., Flower image → \"daisy\")\n",
    "\n",
    "Object detection predicts: Input Image → Multiple (Bounding Box + Label + Confidence Score)\n",
    "\n",
    "Each object in the image gets:\n",
    "- A bounding box\n",
    "- A class label\n",
    "- A confidence score\n",
    "This makes detection structurally more complex than classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a13b84-ad82-4bce-b220-949362aa8df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 20\n",
      "Class names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n"
     ]
    }
   ],
   "source": [
    "# Load Pascal VOC from TFDS\n",
    "# We will use the Pascal VOC 2007 dataset \n",
    "# It contains 20 object classes, bounding box annotations, multiple objects per image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset, info = tfds.load(\n",
    "    \"voc/2007\",\n",
    "    split=\"train\",\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_classes = info.features[\"objects\"][\"label\"].num_classes\n",
    "class_names = info.features[\"objects\"][\"label\"].names\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Class names:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcaf746-56b8-468e-904d-5429f48c51e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (480, 389, 3)\n",
      "Bounding boxes shape: (4, 4)\n",
      "Labels: ['horse', 'person', 'horse', 'person']\n"
     ]
    }
   ],
   "source": [
    "# Inspect One Sample\n",
    "# Bounding boxes are normalized (ymin, xmin, ymax, xmax), multiple objects per image\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "\n",
    "image = sample[\"image\"]\n",
    "boxes = sample[\"objects\"][\"bbox\"]\n",
    "labels = sample[\"objects\"][\"label\"]\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Bounding boxes shape:\", boxes.shape)\n",
    "print(\"Labels:\", [class_names[int(l)] for l in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80982d44-900d-4d84-b7ee-bfecbe38bbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ground truth images to:\n",
      "C:\\Users\\Jason Eckert\\Documents\\cv\\04_detect_segment\\04a_ground_truth\n",
      "Saved: 04a_ground_truth\\ground_truth_0.jpg\n",
      "Saved: 04a_ground_truth\\ground_truth_1.jpg\n",
      "Saved: 04a_ground_truth\\ground_truth_2.jpg\n",
      "Saved: 04a_ground_truth\\ground_truth_3.jpg\n",
      "Saved: 04a_ground_truth\\ground_truth_4.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create Output Folder and Save Function\n",
    "\n",
    "GROUND_TRUTH_DIR = \"04a_ground_truth\"\n",
    "os.makedirs(GROUND_TRUTH_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Saving ground truth images to:\")\n",
    "print(os.path.abspath(GROUND_TRUTH_DIR))\n",
    "\n",
    "# Save Several Examples\n",
    "\n",
    "def save_image_with_boxes(image, boxes, index):\n",
    "    \"\"\"\n",
    "    image: (H, W, 3)\n",
    "    boxes: (num_boxes, 4) normalized ymin,xmin,ymax,xmax\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to float32 [0,1]\n",
    "    image_float = tf.cast(image, tf.float32) / 255.0\n",
    "    image_batch = tf.expand_dims(image_float, axis=0)\n",
    "\n",
    "    boxes_batch = tf.expand_dims(boxes, axis=0)\n",
    "\n",
    "    boxed_image = tf.image.draw_bounding_boxes(\n",
    "        image_batch,\n",
    "        boxes_batch,\n",
    "        colors=[[1.0, 0.0, 0.0]]  # red\n",
    "    )\n",
    "\n",
    "    boxed_image = tf.cast(boxed_image[0] * 255.0, tf.uint8)\n",
    "\n",
    "    encoded = tf.io.encode_jpeg(boxed_image)\n",
    "\n",
    "    filename = os.path.join(GROUND_TRUTH_DIR, f\"ground_truth_{index}.jpg\")\n",
    "    tf.io.write_file(filename, encoded)\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "for i, sample in enumerate(dataset.take(5)):\n",
    "    image = sample[\"image\"]\n",
    "    boxes = sample[\"objects\"][\"bbox\"]\n",
    "\n",
    "    save_image_with_boxes(image, boxes, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7aae3c8-e4ac-46a8-a87f-e78f2240901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained SSD MobileNet (Inference Only)\n",
    "# NOTE:\n",
    "# The warning about pkg_resources being deprecated comes from tensorflow_hub.\n",
    "# It does NOT affect model loading or inference.\n",
    "# It can safely be ignored.\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "\n",
    "print(type(detector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a96736-aac2-40ab-b08a-4c77eb9921de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Inference\n",
    "\n",
    "def run_inference(image):\n",
    "    # Resize but KEEP uint8 dtype\n",
    "    image_resized = tf.image.resize(image, (320, 320))\n",
    "\n",
    "    # tf.image.resize converts to float32 → convert back to uint8\n",
    "    image_resized = tf.cast(image_resized, tf.uint8)\n",
    "\n",
    "    image_resized = tf.expand_dims(image_resized, axis=0)\n",
    "\n",
    "    results = detector(image_resized)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b65d0565-2170-45d6-aa07-356481be628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to:\n",
      "C:\\Users\\Jason Eckert\\Documents\\cv\\04_detect_segment\\04a_ssd_predictions\n",
      "Saved: 04a_ssd_predictions\\prediction_0.jpg\n",
      "Saved: 04a_ssd_predictions\\prediction_1.jpg\n",
      "Saved: 04a_ssd_predictions\\prediction_2.jpg\n",
      "Saved: 04a_ssd_predictions\\prediction_3.jpg\n",
      "Saved: 04a_ssd_predictions\\prediction_4.jpg\n"
     ]
    }
   ],
   "source": [
    "# Saving SSD Predictions\n",
    "\n",
    "PREDICTION_DIR = \"04a_ssd_predictions\"\n",
    "os.makedirs(PREDICTION_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Saving predictions to:\")\n",
    "print(os.path.abspath(PREDICTION_DIR))\n",
    "\n",
    "def save_predictions(image, results, index, threshold=0.5):\n",
    "    image_float = tf.cast(image, tf.float32) / 255.0\n",
    "    image_batch = tf.expand_dims(image_float, axis=0)\n",
    "\n",
    "    boxes = results[\"detection_boxes\"][0]\n",
    "    scores = results[\"detection_scores\"][0]\n",
    "\n",
    "    # Filter by confidence threshold\n",
    "    mask = scores > threshold\n",
    "    boxes = tf.boolean_mask(boxes, mask)\n",
    "\n",
    "    if tf.shape(boxes)[0] == 0:\n",
    "        print(f\"No detections above threshold for image {index}\")\n",
    "        return\n",
    "\n",
    "    boxes_batch = tf.expand_dims(boxes, axis=0)\n",
    "\n",
    "    boxed_image = tf.image.draw_bounding_boxes(\n",
    "        image_batch,\n",
    "        boxes_batch,\n",
    "        colors=[[0.0, 1.0, 0.0]]  # green\n",
    "    )\n",
    "\n",
    "    boxed_image = tf.cast(boxed_image[0] * 255.0, tf.uint8)\n",
    "\n",
    "    encoded = tf.io.encode_jpeg(boxed_image)\n",
    "\n",
    "    filename = os.path.join(PREDICTION_DIR, f\"prediction_{index}.jpg\")\n",
    "    tf.io.write_file(filename, encoded)\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "for i, sample in enumerate(dataset.take(5)):\n",
    "    image = sample[\"image\"]\n",
    "    results = run_inference(image)\n",
    "\n",
    "    save_predictions(image, results, i, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f053d-49fb-4817-b6ac-785018774bda",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "- Anchor boxes\n",
    "- NMS (non-max suppression)\n",
    "- Why detection is computationally heavier than classification\n",
    "\n",
    "# Key Detection Concepts\n",
    "- Confidence Score = Probability the predicted box contains an object.\n",
    "  - Lower threshold → more detections\n",
    "  - Higher threshold → fewer but more confident detections\n",
    "- Non-Max Suppression (NMS) removes overlapping boxes and keeps the best one.\n",
    "- Without NMS: Many boxes would overlap the same object.\n",
    "\n",
    "# Mini Exercise\n",
    "- Change the threshold to 0.3 and re-run predictions.\n",
    "- Increase threshold to 0.8. What happens?\n",
    "- Try .take(10) instead of .take(5).\n",
    "- Compare ground truth vs predictions. Where does SSD struggle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5c04b-73f2-4ec9-8592-8ae416870f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
