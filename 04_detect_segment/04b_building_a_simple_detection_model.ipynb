{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Multi-Output Detection Model\n",
    "- Build a model with multiple outputs\n",
    "- Combine regression and classification loss\n",
    "- Train a simplified detection model\n",
    "- Understand multi-task learning\n",
    "\n",
    "## Why Build a Simplified Model?\n",
    "- Modern detectors (e.g., RetinaNet, YOLO) are complex.\n",
    "- Here, we build a simplified version to understand: Backbone CNN → Classification Head → Bounding Box Regression Head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n",
      "Number of classes: 20\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset, info = tfds.load(\n",
    "    \"voc/2007\",\n",
    "    split=\"train\",\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_classes = info.features[\"objects\"][\"label\"].num_classes\n",
    "class_names = info.features[\"objects\"][\"label\"].names\n",
    "\n",
    "print(\"Dataset loaded.\")\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# Create Small Subset\n",
    "\n",
    "small_ds = dataset.take(500)\n",
    "\n",
    "# Preprocessing\n",
    "# We simplify to resize image to 224x224, keep only ONE object per image (for clarity)\n",
    "\n",
    "def preprocess(sample):\n",
    "    image = tf.image.resize(sample[\"image\"], (224,224))\n",
    "    image = image / 255.0\n",
    "\n",
    "    box = sample[\"objects\"][\"bbox\"][0]\n",
    "    label = sample[\"objects\"][\"label\"][0]\n",
    "\n",
    "    return image, {\n",
    "        \"class_output\": tf.one_hot(label, num_classes),\n",
    "        \"box_output\": box\n",
    "    }\n",
    "\n",
    "train_ds = small_ds.map(preprocess).batch(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "class_output = tf.keras.layers.Dense(\n",
    "    num_classes,\n",
    "    activation=\"softmax\",\n",
    "    name=\"class_output\"\n",
    ")(x)\n",
    "\n",
    "box_output = tf.keras.layers.Dense(\n",
    "    4,\n",
    "    name=\"box_output\"\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=base_model.input,\n",
    "    outputs=[class_output, box_output]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"class_output\": \"categorical_crossentropy\",\n",
    "        \"box_output\": \"mse\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"class_output\": \"accuracy\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "32/32 [==============================] - 7s 109ms/step - loss: 3.2250 - class_output_loss: 2.6408 - box_output_loss: 0.5842 - class_output_accuracy: 0.2740\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 1.5117 - class_output_loss: 1.1842 - box_output_loss: 0.3275 - class_output_accuracy: 0.6800\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.9357 - class_output_loss: 0.7018 - box_output_loss: 0.2339 - class_output_accuracy: 0.8180\n"
     ]
    }
   ],
   "source": [
    "# Train (CPU-safe)\n",
    "\n",
    "history = model.fit(train_ds, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- Why Use MSE for Boxes? Bounding box prediction is a regression task.\n",
    "- Why Separate Losses? Detection is a multi-task learning problem:\n",
    "  - Task 1: Classification\n",
    "  - Task 2: Localization\n",
    "\n",
    "# Reflection Questions\n",
    "- Why might this model perform poorly compared to SSD?\n",
    "- What happens if we unfreeze the backbone?\n",
    "- Why is predicting multiple objects harder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
