{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# Efficient Data Pipelines with tf.data\n",
    "- In earlier chapters, we focused on building, training, and evaluating computer vision models, understanding architectures, etc.\n",
    "- In many production systems the bottleneck is not the model — it is the data pipeline.\n",
    "- If data cannot be delivered to the model efficiently, GPUs sit idle, training slows, costs increase.\n",
    "\n",
    "We'll:\n",
    "- Explain why input pipelines can become ML bottlenecks.\n",
    "- Build efficient data pipelines using tf.data.\n",
    "- Use map() with parallel calls, cache(), shuffle(), batch(), prefetch()\n",
    "- Measure and compare pipeline performance.\n",
    "- Think like an ML engineer optimizing system throughput — not just model accuracy.\n",
    "\n",
    "Each step serves a purpose:\n",
    "- map() → transforms data (resize, normalize)\n",
    "- cache() → avoids recomputation\n",
    "- shuffle() → improves generalization\n",
    "- batch() → enables parallel computation\n",
    "- prefetch() → overlaps preprocessing and training\n",
    "\n",
    "When combined properly, these dramatically improve throughput.\n",
    "\n",
    "This notebook lays the foundation for:\n",
    "- 07b – TensorFlow performance best practices\n",
    "- 07c – Model export and versioning\n",
    "- 07d – Distributed training concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Load Dataset\n",
    "\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
    "\n",
    "# Preprocessing Function\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = image / 255.0\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Pipeline (Slow)\n",
    "\n",
    "ds_train_slow = (\n",
    "    ds_train\n",
    "    .map(preprocess)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Pipeline\n",
    "\n",
    "ds_train_fast = (\n",
    "    ds_train\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(1000)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow pipeline time: 0.26 sec\n",
      "Fast pipeline time: 0.17 sec\n"
     ]
    }
   ],
   "source": [
    "# Timing Comparison\n",
    "\n",
    "def benchmark(dataset, epochs=3):\n",
    "    start = time.time()\n",
    "    for _ in range(epochs):\n",
    "        for _ in dataset:\n",
    "            pass\n",
    "    return time.time() - start\n",
    "\n",
    "slow_time = benchmark(ds_train_slow)\n",
    "fast_time = benchmark(ds_train_fast)\n",
    "\n",
    "print(f\"Slow pipeline time: {slow_time:.2f} sec\")\n",
    "print(f\"Fast pipeline time: {fast_time:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "92/92 [==============================] - 11s 115ms/step - loss: 1.4332 - accuracy: 0.4240 - val_loss: 1.0813 - val_accuracy: 0.5844\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 9s 99ms/step - loss: 1.0144 - accuracy: 0.6059 - val_loss: 0.8204 - val_accuracy: 0.7375\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 10s 104ms/step - loss: 0.7268 - accuracy: 0.7364 - val_loss: 0.5354 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train_fast,\n",
    "    validation_data=ds_train_fast.take(10),\n",
    "    epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
