{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option A: Local Serverless Simulation (FastAPI + Local Model Registry)\n",
    "- Deploy a model as a REST API\n",
    "- Submit inference requests asynchronously\n",
    "- Serverless abstraction = “model service” independent of training\n",
    "- Analogous to Vertex AI from book that runs in cloud environment\n",
    "  \n",
    "First ensure you have a versioned model directory (e.g., model_registry/v_20260215_1530/) from the 07c notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI Server (put the following in a new file called server.py in the 07_training folder)\n",
    "###### MAKE SURE YOU REPLACE THE FILE PATH FOR MODEL_DIR #######\n",
    "\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load latest model\n",
    "MODEL_DIR = \"model_registry/v_20260215_185521\"  # Replace with your saved model folder\n",
    "model = tf.keras.models.load_model(MODEL_DIR)\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(MODEL_DIR, \"metadata.json\")) as f:\n",
    "    metadata = json.load(f)\n",
    "IMG_SIZE = metadata[\"img_size\"]\n",
    "CLASS_NAMES = metadata[\"class_names\"]\n",
    "\n",
    "def preprocess_image(file_bytes):\n",
    "    img = Image.open(io.BytesIO(file_bytes)).convert(\"RGB\")\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img_array = np.array(img)/255.0\n",
    "    return np.expand_dims(img_array, axis=0)\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    bytes_data = await file.read()\n",
    "    img_array = preprocess_image(bytes_data)\n",
    "    preds = model.predict(img_array)\n",
    "    pred_class = CLASS_NAMES[np.argmax(preds)]\n",
    "    return {\"prediction\": pred_class}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these commands in a new Anaconda PowerShell terminal to create a server with a REST API\n",
    "\n",
    "conda activate cv\n",
    "cd Documents\\cv\\07_training\n",
    "uvicorn server:app --reload --port 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "jlxxxpeaT6ea",
    "outputId": "ad4f09e8-bc33-4c92-dc47-5fc73ec12f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'daisy'}\n"
     ]
    }
   ],
   "source": [
    "# Test Predictions (upload flower to server via the REST API, get result in JSON format)\n",
    "# This can be executed directly from this notebook!\n",
    "\n",
    "import requests\n",
    "\n",
    "file_path = \"test_flower.jpg\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    response = requests.post(\"http://127.0.0.1:8000/predict/\", files={\"file\": f})\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option B: WSL + Container Simulation (Advanced)\n",
    "- Simulate cloud-like environment using Docker inside a WSL (Windows Subsystem for Linux) virtual machine of Ubuntu Linux\n",
    "  - We package the same FastAPI app and run it as a Docker container on WSL/Ubuntu — mimicking how Vertex AI jobs run\n",
    "  - We must first install WSL/Ubuntu, then install Docker in Ubuntu\n",
    "- The detailed steps and commands used to set all of this up and utilize the files below are in the class slide deck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dockerfile (no file extension!) with the following contents in your 07_training folder:\n",
    "\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY server.py .\n",
    "COPY model_registry/ ./model_registry/\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create requirements.txt in your 07_training folder (note the locked versions match what we currently use):\n",
    "\n",
    "fastapi\n",
    "uvicorn\n",
    "tensorflow==2.9\n",
    "tensorflow_datasets==4.9\n",
    "protobuf==3.20\n",
    "pillow\n",
    "numpy==1.26\n",
    "python-multipart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and run the container using the following commands in your 07_training folder:\n",
    "\n",
    "docker build -t local-serverless-ml .  # Don't forget the trailing period, which searches for the Dockerfile in the current (.) directory\n",
    "docker run -d -p 8000:8000 --name serverlessml local-serverless-ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'daisy'}\n"
     ]
    }
   ],
   "source": [
    "# Client Requests (Same as Option A)\n",
    "\n",
    "import requests\n",
    "\n",
    "file_path = \"test_flower.jpg\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    response = requests.post(\"http://127.0.0.1:8000/predict/\", files={\"file\": f})\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
