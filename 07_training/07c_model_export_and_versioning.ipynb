{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# Model Export, Versioning, and Reproducibility\n",
    "In production systems, we must save the model, version it, reload it, validate it, prepare it for deployment, and ensure reproducibility.\n",
    "\n",
    "We'll:\n",
    "- Train a small image classifier\n",
    "- Save it using multiple formats\n",
    "- Implement simple versioning\n",
    "- Reload and verify predictions\n",
    "- Export a clean inference-ready artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset (Small Subset for Speed)\n",
    "\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
    "CLASS_NAMES = ds_info.features[\"label\"].names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    ds_val\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "92/92 [==============================] - 11s 112ms/step - loss: 1.4171 - accuracy: 0.4074 - val_loss: 1.1354 - val_accuracy: 0.5354\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 10s 106ms/step - loss: 0.9977 - accuracy: 0.6069 - val_loss: 0.9861 - val_accuracy: 0.6253\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 10s 104ms/step - loss: 0.7439 - accuracy: 0.7285 - val_loss: 0.9684 - val_accuracy: 0.6526\n"
     ]
    }
   ],
   "source": [
    "# Train Briefly\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version: v_20260215_185521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_registry\\v_20260215_185521\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_registry\\v_20260215_185521\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: model_registry\\v_20260215_185521\n"
     ]
    }
   ],
   "source": [
    "# Model Versioning\n",
    "# In production, we never overwrite models, we version them.\n",
    "\n",
    "# Create Version Directory\n",
    "\n",
    "base_dir = \"model_registry\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "version = datetime.now().strftime(\"v_%Y%m%d_%H%M%S\")\n",
    "model_dir = os.path.join(base_dir, version)\n",
    "\n",
    "os.makedirs(model_dir)\n",
    "\n",
    "print(\"Model version:\", version)\n",
    "\n",
    "# Save Full Model (SavedModel Format) - saves architecture, weights, optimizer state, computation graph\n",
    "\n",
    "model.save(model_dir)\n",
    "\n",
    "print(\"Model saved to:\", model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved.\n"
     ]
    }
   ],
   "source": [
    "# Save Metadata (Critical in Production)\n",
    "\n",
    "metadata = {\n",
    "    \"version\": version,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "    \"framework\": \"TensorFlow\",\n",
    "    \"tf_version\": tf.__version__,\n",
    "    \"date_saved\": str(datetime.now())\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Metadata saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Mean prediction difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Reload and Validate\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_dir)\n",
    "\n",
    "sample_batch = next(iter(ds_val))\n",
    "images, labels = sample_batch\n",
    "\n",
    "original_preds = model.predict(images)\n",
    "loaded_preds = loaded_model.predict(images)\n",
    "\n",
    "difference = np.mean(np.abs(original_preds - loaded_preds))\n",
    "\n",
    "print(\"Mean prediction difference:\", difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved to: model_registry\\v_20260215_185521\\weights_only.h5\n"
     ]
    }
   ],
   "source": [
    "# Export Weights Only (Optional Alternative)\n",
    "\n",
    "weights_path = os.path.join(model_dir, \"weights_only.h5\")\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "print(\"Weights saved to:\", weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "Predicted class: dandelion\n"
     ]
    }
   ],
   "source": [
    "# Create Inference-Ready Wrapper\n",
    "# In production, we often separate the training and inference pipelines\n",
    "\n",
    "# Define Inference Function\n",
    "\n",
    "def predict_image(model, image_array):\n",
    "    image = tf.image.resize(image_array, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    preds = model.predict(image)\n",
    "    predicted_class = CLASS_NAMES[np.argmax(preds)]\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Test Inference\n",
    "\n",
    "test_image = images[0]\n",
    "prediction = predict_image(loaded_model, test_image)\n",
    "\n",
    "print(\"Predicted class:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We:\n",
    "- Trained a vision model\n",
    "- Created a versioned model registry\n",
    "- Saved model artifacts\n",
    "- Saved metadata\n",
    "- Reloaded the model\n",
    "- Verified prediction consistency\n",
    "- Built an inference wrapper\n",
    "\n",
    "In real systems:\n",
    "- Models must be reproducible\n",
    "- Models must be versioned\n",
    "- Models must be traceable\n",
    "- Models must be deployable independently of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-5.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m75"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
