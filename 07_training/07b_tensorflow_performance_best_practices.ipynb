{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# Thinking in Tensors and Graphs\n",
    "- Explain why Python loops slow down ML workloads.\n",
    "- Rewrite naïve tensor operations using vectorization.\n",
    "- Use TensorFlow-native ops instead of NumPy inside pipelines.\n",
    "- Understand how @tf.function compiles Python into optimized graphs.\n",
    "- Recognize performance patterns used in production ML systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "GPUs detected: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"GPUs detected:\", gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop time: 2.1757538318634033\n",
      "Vectorized time: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Vectorization Example\n",
    "# Vectorized tensor operations are dramatically faster than Python loops because they execute \n",
    "# in optimized C++ kernels and can leverage parallel hardware.\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = tf.random.uniform((10000, 100))\n",
    "\n",
    "# Python loop (slow)\n",
    "start = time.time()\n",
    "result = []\n",
    "for i in range(10000):\n",
    "    result.append(tf.reduce_sum(x[i]))\n",
    "loop_time = time.time() - start\n",
    "\n",
    "# Vectorized (fast)\n",
    "start = time.time()\n",
    "result2 = tf.reduce_sum(x, axis=1)\n",
    "vector_time = time.time() - start\n",
    "\n",
    "print(\"Loop time:\", loop_time)\n",
    "print(\"Vectorized time:\", vector_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow version time: 0.02286243438720703\n",
      "Fast version time: 0.0030002593994140625\n"
     ]
    }
   ],
   "source": [
    "# Simulated Image Batch\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 128\n",
    "\n",
    "images = tf.random.uniform((BATCH_SIZE, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Naïve Python Loop (Bad Practice)\n",
    "\n",
    "def slow_center(images):\n",
    "    output = []\n",
    "    for img in images:\n",
    "        mean = tf.reduce_mean(img)\n",
    "        output.append(img - mean)\n",
    "    return tf.stack(output)\n",
    "\n",
    "start = time.time()\n",
    "_ = slow_center(images)\n",
    "slow_time = time.time() - start\n",
    "\n",
    "print(\"Slow version time:\", slow_time)\n",
    "\n",
    "# Vectorized Version (Good Practice)\n",
    "\n",
    "def fast_center(images):\n",
    "    mean = tf.reduce_mean(images, axis=(1,2,3), keepdims=True)\n",
    "    return images - mean\n",
    "\n",
    "start = time.time()\n",
    "_ = fast_center(images)\n",
    "fast_time = time.time() - start\n",
    "\n",
    "print(\"Fast version time:\", fast_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Ops vs NumPy Ops\n",
    "# Mixing NumPy inside a TensorFlow pipeline forces execution back to Python.\n",
    "\n",
    "# NumPy in tf.data (Bad Pattern)\n",
    "\n",
    "def numpy_preprocess(image, label):\n",
    "    image = image.numpy() / 255.0\n",
    "    return image, label\n",
    "\n",
    "# TensorFlow-Native Version (Good Pattern)\n",
    "\n",
    "def tf_preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544 μs ± 7.01 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# tf.function Speedup\n",
    "# TensorFlow can convert Python functions into optimized computation graphs for faster execution\n",
    "\n",
    "@tf.function\n",
    "def compute(x):\n",
    "    return tf.reduce_sum(tf.square(x))\n",
    "\n",
    "x = tf.random.uniform((1000, 1000))\n",
    "\n",
    "%timeit compute(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution time: 0.0010116100311279297\n",
      "Graph execution time: 0.0\n"
     ]
    }
   ],
   "source": [
    "# From Eager to Graph Execution (@tf.function)\n",
    "# TensorFlow 2 runs eagerly by default.\n",
    "# @tf.function: \n",
    "# --> Traces the function\n",
    "# --> Builds computation graph\n",
    "# --> Optimizes execution\n",
    "# --> Removes Python overhead\n",
    "# Production systems rely on graph execution.\n",
    "\n",
    "# Eager Function\n",
    "\n",
    "def compute_loss(x):\n",
    "    return tf.reduce_sum(tf.square(x))\n",
    "\n",
    "x = tf.random.uniform((1000, 1000))\n",
    "\n",
    "start = time.time()\n",
    "_ = compute_loss(x)\n",
    "eager_time = time.time() - start\n",
    "\n",
    "print(\"Eager execution time:\", eager_time)\n",
    "\n",
    "# Graph-Compiled Function\n",
    "\n",
    "@tf.function\n",
    "def compute_loss_graph(x):\n",
    "    return tf.reduce_sum(tf.square(x))\n",
    "\n",
    "# First call includes tracing cost\n",
    "compute_loss_graph(x)\n",
    "\n",
    "start = time.time()\n",
    "_ = compute_loss_graph(x)\n",
    "graph_time = time.time() - start\n",
    "\n",
    "print(\"Graph execution time:\", graph_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager training time (500 steps): 3.2288 sec\n",
      "Graph training time (500 steps): 0.4553 sec\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Simple dense model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Synthetic batch\n",
    "\n",
    "x = tf.random.uniform((64, 100))\n",
    "y = tf.random.uniform((64, 10))\n",
    "\n",
    "# Eager Training Step\n",
    "\n",
    "def train_step_eager(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x, training=True)\n",
    "        loss = loss_fn(y, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Graph-Compiled Training Step\n",
    "\n",
    "@tf.function\n",
    "def train_step_graph(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x, training=True)\n",
    "        loss = loss_fn(y, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Benchmark Function\n",
    "\n",
    "def benchmark(func, x, y, n_iters=500):\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        func(x, y)\n",
    "    return time.time() - start\n",
    "\n",
    "# Warmup (Important for Fair Comparison) - first call includes tracing cost\n",
    "\n",
    "train_step_graph(x, y)\n",
    "\n",
    "# Run Benchmark\n",
    "\n",
    "eager_time = benchmark(train_step_eager, x, y)\n",
    "graph_time = benchmark(train_step_graph, x, y)\n",
    "\n",
    "print(f\"Eager training time (500 steps): {eager_time:.4f} sec\")\n",
    "print(f\"Graph training time (500 steps): {graph_time:.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying @tf.function to a Training Step\n",
    "\n",
    "# Minimal Model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(128,128,3)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Custom Training Step\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_fn(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Performance Checklist\n",
    "\n",
    "When building ML pipelines:\n",
    "\n",
    "✅ Batch operations\n",
    "\n",
    "✅ Use tf.data\n",
    "\n",
    "✅ Avoid Python loops over tensors\n",
    "\n",
    "✅ Prefer TensorFlow ops over NumPy\n",
    "\n",
    "✅ Use @tf.function for custom training steps\n",
    "\n",
    "✅ Profile before optimizing\n",
    "\n",
    "✅ Keep preprocessing on-device (not Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
