{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# Flowers Image Classification using a Neural Network\n",
    "In this notebook, we show how to build a neural network to classify the tf-flowers dataset.\n",
    "Much of the data exploration was done in the companion notebook: 02a_machine_perception.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "f25e3267-1495-48f8-d6e1-4da24dd41755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "No GPU detected, running on CPU.\n",
      "Classes (5): ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']\n",
      "Train samples: 2936\n",
      "Validation samples: 734\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 0: Imports & environment\n",
    "# ========================================================\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# -------------------------------\n",
    "# Windows TensorFlow stability\n",
    "# -------------------------------\n",
    "if platform.system() == \"Windows\":\n",
    "    # Disable GPU to prevent native crashes\n",
    "    try:\n",
    "        tf.config.set_visible_devices([], 'GPU')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Limit threading to avoid MKL / OpenMP conflicts\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "# Output directory for generated images & CSVs\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU devices available:\", tf.config.list_physical_devices('GPU'))\n",
    "else:\n",
    "    print(\"No GPU detected, running on CPU.\")\n",
    "\n",
    "# ========================================================\n",
    "# Step 1: Load TFDS flowers dataset\n",
    "# ========================================================\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    "    data_dir=Path(\"data\") / \"tfds\"\n",
    ")\n",
    "\n",
    "CLASS_NAMES = ds_info.features[\"label\"].names\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(f\"Classes ({NUM_CLASSES}): {CLASS_NAMES}\")\n",
    "print(f\"Train samples: {ds_info.splits['train'].num_examples * 0.8:.0f}\")\n",
    "print(f\"Validation samples: {ds_info.splits['train'].num_examples * 0.2:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 150528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 752645    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 752,645\n",
      "Trainable params: 752,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 2: Simple dataset preprocessing\n",
    "# ========================================================\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 224, 224, 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def preprocess(img, label):\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "train_dataset = ds_train.map(preprocess).batch(BATCH_SIZE)\n",
    "val_dataset = ds_val.map(preprocess).batch(BATCH_SIZE)\n",
    "\n",
    "# ========================================================\n",
    "# Step 3: Define simple neural network\n",
    "# ========================================================\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "184/184 [==============================] - 3s 14ms/step - loss: 18.3946 - accuracy: 0.3283 - val_loss: 17.5353 - val_accuracy: 0.3624\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 10.2625 - accuracy: 0.4251 - val_loss: 9.1255 - val_accuracy: 0.4033\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 8.8731 - accuracy: 0.4469 - val_loss: 12.2511 - val_accuracy: 0.3815\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 12.3787 - accuracy: 0.4469 - val_loss: 13.5211 - val_accuracy: 0.4210\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 2s 8ms/step - loss: 9.4573 - accuracy: 0.5041 - val_loss: 9.8265 - val_accuracy: 0.4101\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 4: Train the model\n",
    "# ========================================================\n",
    "EPOCHS = 5  # adjust for demo speed\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics saved to C:\\Users\\Jason Eckert\\Documents\\cv\\02_ml_models\\outputs\\training_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 5: Export training metrics to CSV\n",
    "# ========================================================\n",
    "import csv\n",
    "\n",
    "metrics_csv = OUT_DIR / \"training_metrics.csv\"\n",
    "fieldnames = ['epoch'] + list(history.history.keys())\n",
    "\n",
    "with open(metrics_csv, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(EPOCHS):\n",
    "        row = {'epoch': i+1}\n",
    "        for key in history.history:\n",
    "            row[key] = history.history[key][i]\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Training metrics saved to {metrics_csv.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction grid saved to C:\\Users\\Jason Eckert\\Documents\\cv\\02_ml_models\\outputs\\prediction_grid.png\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 6: Visualize predictions (PIL grid)\n",
    "# ========================================================\n",
    "def save_prediction_grid(dataset, model, out_path, num_images=15, grid_shape=(3,5)):\n",
    "    imgs, labels, preds, probs = [], [], [], []\n",
    "    \n",
    "    for idx, (img, label) in enumerate(dataset.unbatch().take(num_images)):\n",
    "        batch_img = tf.expand_dims(img, 0)\n",
    "        pred = model.predict(batch_img, verbose=0)[0]\n",
    "        pred_idx = int(tf.argmax(pred))\n",
    "        imgs.append((img.numpy()*255).astype(np.uint8))\n",
    "        labels.append(int(label))\n",
    "        preds.append(pred_idx)\n",
    "        probs.append(pred[pred_idx])\n",
    "    \n",
    "    # PIL image grid\n",
    "    rows, cols = grid_shape\n",
    "    thumb_h, thumb_w = IMG_HEIGHT, IMG_WIDTH\n",
    "    grid_img = Image.new(\"RGB\", (cols*thumb_w, rows*thumb_h), \"white\")\n",
    "    draw = ImageDraw.Draw(grid_img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        r, c = divmod(i, cols)\n",
    "        img = Image.fromarray(imgs[i])\n",
    "        grid_img.paste(img, (c*thumb_w, r*thumb_h))\n",
    "        text = f\"{CLASS_NAMES[labels[i]]} -> {CLASS_NAMES[preds[i]]} ({probs[i]:.2f})\"\n",
    "        draw.text((c*thumb_w + 5, r*thumb_h + 5), text, fill=\"black\", font=font)\n",
    "    \n",
    "    grid_img.save(out_path)\n",
    "    print(f\"Prediction grid saved to {out_path.resolve()}\")\n",
    "\n",
    "save_prediction_grid(val_dataset, model, OUT_DIR / \"prediction_grid.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weight visualization for dandelion\n",
      "Saved weight visualization for daisy\n",
      "Saved weight visualization for tulips\n",
      "Saved weight visualization for sunflowers\n",
      "Saved weight visualization for roses\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 7: Visualize linear layer weights (PIL)\n",
    "# ========================================================\n",
    "def save_trained_weights(model, out_dir):\n",
    "    weights = model.layers[1].get_weights()[0]  # Dense layer weights\n",
    "    min_wt = np.min(weights)\n",
    "    max_wt = np.max(weights)\n",
    "    scaled_weights = (weights - min_wt) / (max_wt - min_wt)\n",
    "    \n",
    "    for i in range(NUM_CLASSES):\n",
    "        w_img = (scaled_weights[:, i].reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(w_img)\n",
    "        img.save(out_dir / f\"weights_{CLASS_NAMES[i]}.png\")\n",
    "        print(f\"Saved weight visualization for {CLASS_NAMES[i]}\")\n",
    "\n",
    "save_trained_weights(model, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtsR1Fzbh4ff"
   },
   "source": [
    "## Now, let's go more in depth\n",
    "### Setup: Install Keras Tuner: `conda install -c conda-forge keras-tuner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JUV92GTvyj2",
    "outputId": "37c0b535-f3dd-4a41-e611-2f2345bd3fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Imports\n",
    "# ========================================================\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import csv\n",
    "import keras_tuner as kt\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "OUT_DIR = Path(\"outputs_nn\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 224, 224, 3\n",
    "CLASS_NAMES = None\n",
    "\n",
    "# ========================================================\n",
    "# Step 1: Load TFDS flowers dataset\n",
    "# ========================================================\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    "    data_dir=Path(\"data\") / \"tfds\"\n",
    ")\n",
    "\n",
    "CLASS_NAMES = ds_info.features[\"label\"].names\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(\"Classes:\", CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Step 2: Preprocess datasets\n",
    "# ========================================================\n",
    "BATCH_SIZE = 32\n",
    "def preprocess(img, label):\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "train_dataset = ds_train.map(preprocess).batch(BATCH_SIZE)\n",
    "val_dataset = ds_val.map(preprocess).batch(BATCH_SIZE)\n",
    "\n",
    "# ========================================================\n",
    "# Step 3: Parameterized NN trainer\n",
    "# ========================================================\n",
    "def train_nn_model(train_ds, val_ds, num_hidden=128, lrate=0.001, l1=0.0, l2=0.0, epochs=5):\n",
    "    reg = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        tf.keras.layers.Dense(num_hidden, activation='relu', kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=reg)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "    \n",
    "    # Save metrics CSV\n",
    "    metrics_csv = OUT_DIR / f\"metrics_hidden{num_hidden}_l1{l1}_l2{l2}.csv\"\n",
    "    fieldnames = ['epoch'] + list(history.history.keys())\n",
    "    with open(metrics_csv, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(epochs):\n",
    "            row = {'epoch': i+1}\n",
    "            for key in history.history:\n",
    "                row[key] = history.history[key][i]\n",
    "            writer.writerow(row)\n",
    "    print(f\"Training metrics saved to {metrics_csv.resolve()}\")\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "92/92 [==============================] - 7s 70ms/step - loss: 2.2904 - accuracy: 0.3569 - val_loss: 1.4229 - val_accuracy: 0.4251\n",
      "Epoch 2/5\n",
      "92/92 [==============================] - 6s 63ms/step - loss: 1.3279 - accuracy: 0.4571 - val_loss: 1.3820 - val_accuracy: 0.4305\n",
      "Epoch 3/5\n",
      "92/92 [==============================] - 6s 66ms/step - loss: 1.2537 - accuracy: 0.4826 - val_loss: 1.4216 - val_accuracy: 0.4292\n",
      "Epoch 4/5\n",
      "92/92 [==============================] - 6s 68ms/step - loss: 1.2016 - accuracy: 0.5089 - val_loss: 1.4436 - val_accuracy: 0.4305\n",
      "Epoch 5/5\n",
      "92/92 [==============================] - 6s 68ms/step - loss: 1.1609 - accuracy: 0.5307 - val_loss: 1.4624 - val_accuracy: 0.4482\n",
      "Training metrics saved to C:\\Users\\Jason Eckert\\Documents\\cv\\02_ml_models\\outputs_nn\\metrics_hidden128_l10.0_l20.0.csv\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 4: Train examples\n",
    "# ========================================================\n",
    "model1, _ = train_nn_model(train_dataset, val_dataset, num_hidden=128, lrate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "92/92 [==============================] - 11s 118ms/step - loss: 2.9730 - accuracy: 0.3341 - val_loss: 1.5295 - val_accuracy: 0.4101\n",
      "Epoch 2/5\n",
      "92/92 [==============================] - 12s 125ms/step - loss: 1.4875 - accuracy: 0.4288 - val_loss: 1.4068 - val_accuracy: 0.4632\n",
      "Epoch 3/5\n",
      "92/92 [==============================] - 11s 124ms/step - loss: 1.3712 - accuracy: 0.4547 - val_loss: 1.3991 - val_accuracy: 0.4578\n",
      "Epoch 4/5\n",
      "92/92 [==============================] - 12s 125ms/step - loss: 1.3074 - accuracy: 0.4850 - val_loss: 1.3787 - val_accuracy: 0.4591\n",
      "Epoch 5/5\n",
      "92/92 [==============================] - 12s 126ms/step - loss: 1.2448 - accuracy: 0.5112 - val_loss: 1.3063 - val_accuracy: 0.4823\n",
      "Training metrics saved to C:\\Users\\Jason Eckert\\Documents\\cv\\02_ml_models\\outputs_nn\\metrics_hidden256_l10.0_l20.0.csv\n"
     ]
    }
   ],
   "source": [
    "model2, _ = train_nn_model(train_dataset, val_dataset, num_hidden=256, lrate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "92/92 [==============================] - 11s 120ms/step - loss: 2.7771 - accuracy: 0.3062 - val_loss: 1.8763 - val_accuracy: 0.3079\n",
      "Epoch 2/5\n",
      "92/92 [==============================] - 12s 126ms/step - loss: 1.6801 - accuracy: 0.3900 - val_loss: 1.7608 - val_accuracy: 0.3501\n",
      "Epoch 3/5\n",
      "92/92 [==============================] - 12s 128ms/step - loss: 1.5768 - accuracy: 0.4547 - val_loss: 1.7842 - val_accuracy: 0.3774\n",
      "Epoch 4/5\n",
      "92/92 [==============================] - 12s 127ms/step - loss: 1.5227 - accuracy: 0.4598 - val_loss: 1.6926 - val_accuracy: 0.4019\n",
      "Epoch 5/5\n",
      "92/92 [==============================] - 12s 130ms/step - loss: 1.4967 - accuracy: 0.4768 - val_loss: 1.6218 - val_accuracy: 0.4019\n",
      "Training metrics saved to C:\\Users\\Jason Eckert\\Documents\\cv\\02_ml_models\\outputs_nn\\metrics_hidden128_l10.0_l20.001.csv\n"
     ]
    }
   ],
   "source": [
    "model3, _ = train_nn_model(train_dataset, val_dataset, num_hidden=128, lrate=0.0001, l2=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction grid saved to C:\\Users\\Jason Eckert\\Documents\\cv\\02_ml_models\\outputs_nn\\prediction_grid_nn.png\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 5: Prediction grid (PIL)\n",
    "# ========================================================\n",
    "def save_prediction_grid(dataset, model, out_path, num_images=15, grid_shape=(3,5)):\n",
    "    imgs, labels, preds, probs = [], [], [], []\n",
    "    for idx, (img, label) in enumerate(dataset.unbatch().take(num_images)):\n",
    "        batch_img = tf.expand_dims(img, 0)\n",
    "        pred = model.predict(batch_img, verbose=0)[0]\n",
    "        pred_idx = int(tf.argmax(pred))\n",
    "        imgs.append((img.numpy()*255).astype(np.uint8))\n",
    "        labels.append(int(label))\n",
    "        preds.append(pred_idx)\n",
    "        probs.append(pred[pred_idx])\n",
    "    rows, cols = grid_shape\n",
    "    grid_img = Image.new(\"RGB\", (cols*IMG_WIDTH, rows*IMG_HEIGHT), \"white\")\n",
    "    draw = ImageDraw.Draw(grid_img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    for i in range(len(imgs)):\n",
    "        r, c = divmod(i, cols)\n",
    "        img = Image.fromarray(imgs[i])\n",
    "        grid_img.paste(img, (c*IMG_WIDTH, r*IMG_HEIGHT))\n",
    "        text = f\"{CLASS_NAMES[labels[i]]} -> {CLASS_NAMES[preds[i]]} ({probs[i]:.2f})\"\n",
    "        draw.text((c*IMG_WIDTH + 5, r*IMG_HEIGHT + 5), text, fill=\"black\", font=font)\n",
    "    grid_img.save(out_path)\n",
    "    print(f\"Prediction grid saved to {out_path.resolve()}\")\n",
    "\n",
    "save_prediction_grid(val_dataset, model3, OUT_DIR / \"prediction_grid_nn.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weight visualization for dandelion\n",
      "Saved weight visualization for daisy\n",
      "Saved weight visualization for tulips\n",
      "Saved weight visualization for sunflowers\n",
      "Saved weight visualization for roses\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Step 6: Linear layer weight visualization\n",
    "# ========================================================\n",
    "def save_trained_weights(model, out_dir):\n",
    "    weights = model.layers[1].get_weights()[0]  # Dense layer weights\n",
    "    min_wt = np.min(weights)\n",
    "    max_wt = np.max(weights)\n",
    "    scaled_weights = (weights - min_wt) / (max_wt - min_wt)\n",
    "    for i in range(NUM_CLASSES):\n",
    "        w_img = (scaled_weights[:, i].reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(w_img)\n",
    "        img.save(out_dir / f\"weights_hidden{i}.png\")\n",
    "        print(f\"Saved weight visualization for {CLASS_NAMES[i]}\")\n",
    "\n",
    "save_trained_weights(model3, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPCx8a-IZpUd"
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SSZvX-BZi5Eg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 05s]\n",
      "val_accuracy: 0.42643052339553833\n",
      "\n",
      "Best val_accuracy So Far: 0.4564032554626465\n",
      "Total elapsed time: 00h 02m 24s\n",
      "Best hyperparameters: {'num_hidden': 256, 'l2': 0.0, 'lrate': 0.0001}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 150528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               38535424  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,536,709\n",
      "Trainable params: 38,536,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Optional: Hyperparameter Tuning Demo (CPU-friendly)\n",
    "# ========================================================\n",
    "\n",
    "# Take a small subset for demonstration\n",
    "train_subset = train_dataset.take(200)\n",
    "val_subset = val_dataset.take(50)\n",
    "\n",
    "def build_tuned_model(hp):\n",
    "    num_hidden = hp.Int('num_hidden', 32, 256, step=32)\n",
    "    l2 = hp.Choice('l2', values=[0.0, 0.001, 0.01])\n",
    "    lrate = hp.Float('lrate', 1e-4, 1e-2, sampling='log')\n",
    "    reg = tf.keras.regularizers.l2(l2)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        tf.keras.layers.Dense(num_hidden, activation='relu', kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=reg)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_tuned_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,  # keep low for CPU demo\n",
    "    num_initial_points=1,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search(train_subset, validation_data=val_subset, epochs=3)\n",
    "\n",
    "# Get top hyperparameters and model\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "print(\"Best hyperparameters:\", best_hp.values)\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71kBPOGuSj95"
   },
   "source": [
    "## Deep Neural Network\n",
    "### Setup: Install Pandas: `conda install -c conda-forge pandas`\n",
    "Let's train a DNN. We will parameterize the number of layers, and the number of nodes in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "f26lxDv5Srao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "92/92 [==============================] - 7s 67ms/step - loss: 1.8526 - accuracy: 0.3028 - val_loss: 2.0764 - val_accuracy: 0.3420\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 6s 64ms/step - loss: 1.6986 - accuracy: 0.3386 - val_loss: 1.5611 - val_accuracy: 0.4046\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 6s 67ms/step - loss: 1.6362 - accuracy: 0.3808 - val_loss: 1.5855 - val_accuracy: 0.3842\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 6s 69ms/step - loss: 1.5831 - accuracy: 0.3910 - val_loss: 1.5038 - val_accuracy: 0.4768\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 6s 69ms/step - loss: 1.5521 - accuracy: 0.4063 - val_loss: 1.4514 - val_accuracy: 0.4632\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 6s 69ms/step - loss: 1.5135 - accuracy: 0.4292 - val_loss: 1.6235 - val_accuracy: 0.3774\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 6s 69ms/step - loss: 1.4737 - accuracy: 0.4380 - val_loss: 1.4608 - val_accuracy: 0.4591\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 6s 69ms/step - loss: 1.4548 - accuracy: 0.4448 - val_loss: 1.4909 - val_accuracy: 0.4373\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 6s 68ms/step - loss: 1.4232 - accuracy: 0.4792 - val_loss: 1.4656 - val_accuracy: 0.4646\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 6s 69ms/step - loss: 1.4101 - accuracy: 0.4710 - val_loss: 1.5070 - val_accuracy: 0.4441\n",
      "\n",
      "Final training metrics:\n",
      "loss: 1.4101\n",
      "accuracy: 0.4710\n",
      "val_loss: 1.5070\n",
      "val_accuracy: 0.4441\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Deep Neural Network (DNN) example - CPU-friendly, TFDS\n",
    "# ========================================================\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 224, 224, 3\n",
    "\n",
    "# Use the same TFDS flowers dataset from previous notebook\n",
    "def preprocess(img, label):\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "train_dataset = ds_train.map(preprocess).batch(BATCH_SIZE)\n",
    "eval_dataset = ds_val.map(preprocess).batch(BATCH_SIZE)\n",
    "\n",
    "# ========================================================\n",
    "# Function to build/train DNN with arbitrary hidden layers\n",
    "# ========================================================\n",
    "def train_and_evaluate_dnn(batch_size=32,\n",
    "                           lrate=0.0001,\n",
    "                           l1=0,\n",
    "                           l2=0.001,\n",
    "                           dropout_prob=0.4,\n",
    "                           num_hidden=[64, 16],\n",
    "                           epochs=10):\n",
    "    regularizer = tf.keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "    \n",
    "    # Build sequential model\n",
    "    layers = [tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "                                      name='input_pixels')]\n",
    "    \n",
    "    # Add hidden layers with BatchNorm, ReLU, and Dropout\n",
    "    for hno, nodes in enumerate(num_hidden):\n",
    "        layers.extend([\n",
    "            tf.keras.layers.Dense(nodes, kernel_regularizer=regularizer,\n",
    "                                  name=f'hidden_dense_{hno}'),\n",
    "            tf.keras.layers.BatchNormalization(scale=False, center=False,\n",
    "                                               name=f'batchnorm_dense_{hno}'),\n",
    "            tf.keras.layers.Activation('relu', name=f'relu_dense_{hno}'),\n",
    "            tf.keras.layers.Dropout(rate=dropout_prob, name=f'dropout_dense_{hno}')\n",
    "        ])\n",
    "    \n",
    "    # Output layer\n",
    "    layers.append(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', \n",
    "                                        kernel_regularizer=regularizer,\n",
    "                                        name='flower_prob'))\n",
    "    \n",
    "    model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(train_dataset, validation_data=eval_dataset, epochs=epochs)\n",
    "    \n",
    "    # Export CSV for plotting outside matplotlib\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(\"dnn_training_history.csv\", index=False)\n",
    "    \n",
    "    # Print some key metrics in terminal for quick inspection\n",
    "    print(\"\\nFinal training metrics:\")\n",
    "    for key, value in history.history.items():\n",
    "        print(f\"{key}: {value[-1]:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ========================================================\n",
    "# Train a simple DNN with 2 hidden layers\n",
    "# ========================================================\n",
    "model = train_and_evaluate_dnn(num_hidden=[64, 16], dropout_prob=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9U0ob6HLUAX"
   },
   "source": [
    "## Diagrams (Key Concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqW02djMUpto",
    "outputId": "df850b31-c29f-42e4-e8ce-9eb9d24bca0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved diagrams\\sigmoid_activation.png\n",
      "Saved diagrams\\relu_activation.png\n",
      "Saved diagrams\\elu_activation.png\n",
      "Saved diagrams\\linear_model_summary.png\n",
      "Saved diagrams\\small_deep_model_summary.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Create a subfolder for diagrams\n",
    "DIAGRAM_DIR = \"diagrams\"\n",
    "os.makedirs(DIAGRAM_DIR, exist_ok=True)\n",
    "\n",
    "# ===============================\n",
    "# Activation Functions Diagrams\n",
    "# ===============================\n",
    "\n",
    "x = np.arange(-10.0, 10.0, 0.1)\n",
    "\n",
    "activations = {\n",
    "    'sigmoid': {\n",
    "        'func': tf.keras.activations.sigmoid,\n",
    "        'desc': (\"Sigmoid squashes inputs to [0,1]; extreme negatives -> 0, positives -> 1. \"\n",
    "                 \"Good for probabilities but can cause vanishing gradients.\")\n",
    "    },\n",
    "    'relu': {\n",
    "        'func': tf.keras.activations.relu,\n",
    "        'desc': (\"ReLU outputs 0 for negatives, linear for positives. \"\n",
    "                 \"Common in hidden layers, avoids vanishing gradients.\")\n",
    "    },\n",
    "    'elu': {\n",
    "        'func': tf.keras.activations.elu,\n",
    "        'desc': (\"ELU is smooth for negatives, linear for positives; improves learning speed/stability.\")\n",
    "    }\n",
    "}\n",
    "\n",
    "for name, info in activations.items():\n",
    "    y = info['func'](x).numpy()\n",
    "    y_min, y_max = np.min(y), np.max(y)\n",
    "    y_scaled = ((y - y_min) / (y_max - y_min) * 255).astype(np.uint8)\n",
    "    \n",
    "    width, height = 500, 300\n",
    "    img = Image.new(\"RGB\", (width, height), color=\"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Draw axes\n",
    "    draw.line((50, 0, 50, height), fill=\"black\")      # y-axis\n",
    "    draw.line((0, height-50, width, height-50), fill=\"black\")  # x-axis\n",
    "    \n",
    "    # Draw curve\n",
    "    for i in range(len(x)-1):\n",
    "        x0 = int(i / len(x) * (width-60)) + 50\n",
    "        y0 = height-50 - int(y_scaled[i] / 255 * (height-60))\n",
    "        x1 = int((i+1) / len(x) * (width-60)) + 50\n",
    "        y1 = height-50 - int(y_scaled[i+1] / 255 * (height-60))\n",
    "        draw.line((x0, y0, x1, y1), fill=\"blue\", width=2)\n",
    "    \n",
    "    # Title and description\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 14)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    draw.text((10, 10), f\"{name} activation\", fill=\"black\", font=font)\n",
    "    draw.text((10, height-45), info['desc'], fill=\"black\", font=font)\n",
    "    \n",
    "    # Save PNG in subfolder\n",
    "    filepath = os.path.join(DIAGRAM_DIR, f\"{name}_activation.png\")\n",
    "    img.save(filepath)\n",
    "    print(f\"Saved {filepath}\")\n",
    "\n",
    "# ===============================\n",
    "# Linear vs Small Deep Model\n",
    "# ===============================\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 224, 224, 3\n",
    "num_classes = 5\n",
    "\n",
    "linear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "], name='linear_model')\n",
    "\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "], name='small_deep_model')\n",
    "\n",
    "def export_model_summary_png(model, filename):\n",
    "    summary_lines = []\n",
    "    model.summary(print_fn=lambda x: summary_lines.append(x))\n",
    "    summary_text = \"\\n\".join(summary_lines)\n",
    "    \n",
    "    img = Image.new(\"RGB\", (700, 200), color=\"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 12)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    y_text = 5\n",
    "    for line in summary_text.split(\"\\n\"):\n",
    "        draw.text((5, y_text), line, fill=\"black\", font=font)\n",
    "        y_text += 14\n",
    "\n",
    "    filepath = os.path.join(DIAGRAM_DIR, filename)\n",
    "    img.save(filepath)\n",
    "    print(f\"Saved {filepath}\")\n",
    "\n",
    "export_model_summary_png(linear_model, \"linear_model_summary.png\")\n",
    "export_model_summary_png(deep_model, \"small_deep_model_summary.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs",
    "BtsR1Fzbh4ff",
    "GPCx8a-IZpUd",
    "X9U0ob6HLUAX"
   ],
   "name": "02b_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
